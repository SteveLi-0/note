# MTCS and MPDM
## MCTS
**Tactical Cooperative Planning for Autonomous Highway Driving using Monte-Carlo Tree Search**

### 基础的MCTS算法

蒙特卡罗树搜索（Monte Carlo Tree Search, MCTS）是一种通过随机采样来寻找最优决策的算法。它在处理决策问题，特别是需要在不确定环境中进行决策的问题时表现出色。MCTS主要由以下四个步骤组成：选择、扩展、模拟和反向传播。

#### 1. 选择（Selection）

选择过程基于已有的搜索树，按照一定的策略从根节点开始选择子节点，直到到达一个叶节点。在选择过程中，常用的策略是上置信界（Upper Confidence Bound, UCB1），其公式为：

\[ UCB1 = \frac{v_i}{n_i} + c \sqrt{\frac{\ln N}{n_i}} \]

其中：
- \( v_i \) 是节点 \( i \) 的价值。
- \( n_i \) 是节点 \( i \) 被访问的次数。
- \( N \) 是父节点被访问的总次数。
- \( c \) 是一个调节参数，控制探索与利用之间的平衡。

通过这个策略，MCTS在每个决策点上选择一个具有最大UCB1值的节点，从而在保证一定探索的同时，更倾向于选择那些已经表现较好的节点。

#### 2. 扩展（Expansion）

当到达一个叶节点后，如果该节点还没有完全扩展（即该节点还有未尝试过的动作），则从该节点选择一个未尝试过的动作，并生成新的子节点进行扩展。这个新节点代表了一个新的状态，等待进一步的模拟和评估。

#### 3. 模拟（Simulation）

从新扩展的叶节点开始，进行模拟。模拟过程通常使用一个默认策略（例如随机选择动作）进行游戏或场景的模拟，直到到达终端状态（如胜利、失败或其他结束条件）。模拟的结果将用于评估该叶节点的价值。

#### 4. 反向传播（Backpropagation）

在模拟结束后，根据模拟的结果更新从叶节点到根节点路径上所有节点的价值。这是通过累积模拟结果来完成的，具体方法是将模拟的结果（如胜利或失败）反向传播到搜索树中的每个节点，以更新其访问次数和价值。

### 算法优势

MCTS具有以下优势，使其特别适用于自动驾驶和其他复杂的决策问题：

- **随时性（Anytime）**：MCTS可以在任何时候停止，并提供当前最好的决策结果。尽管结果可能不是最优的，但总是有效的。
- **并行性（Parallel）**：MCTS可以高度并行化，允许同时进行多次迭代或多次模拟，从而加快计算速度。
- **适应性（Adaptive）**：MCTS能够根据不同的情境调整决策策略，适应各种复杂的决策环境。
- **灵活性（Flexible）**：MCTS可以处理合作和对抗性行为，根据定义的成本函数生成不同的行为模式。

#### 总结

MCTS作为一种强大的决策算法，通过选择、扩展、模拟和反向传播四个步骤，在处理复杂决策问题时表现出色。其随时性、并行性、适应性和灵活性，使其特别适用于自动驾驶等需要实时决策的领域。通过适当的扩展和调整，MCTS能够在动态和不确定的环境中实现高效的合作规划。

### Extensions for Autonomous Driving Domain

在自动驾驶领域，为了使MCTS算法能够有效地应用于合作规划和实时决策，需要进行一些特别的调整和扩展。这部分内容主要介绍了如何调整标准MCTS算法，使其适用于自动驾驶场景中的合作规划。

#### 1. Selection（选择）

选择过程仍然使用标准的UCB1算法，但为了适应自动驾驶的场景，需要将所有效用归一化到0到1之间，以便在每个决策节点进行选择。这确保了算法能够在多种情况下有效工作。

#### 2. Simultaneous Actions and Information Sets（同时动作和信息集）

在自动驾驶场景中，所有车辆在每个阶段同时决定采取的行动。由于无法在树结构中表示同步动作，因此需要将决策过程序列化处理。每辆车依次决定自己的动作，并在最后一辆车决定后进行模拟。在这个过程中，后面的车辆可以根据前面车辆的决策调整策略。为了防止这种情况，所有节点共享相同的信息集，并在回溯阶段统计数据，确保策略的一致性。

#### 3. Default Policy（默认策略）

在模拟过程中，假设所有车辆都遵循智能驾驶模型（Intelligent Driver Model, IDM）。这种默认策略为模拟交通场景提供了合理的基础，如果没有车辆进一步变更车道，则可以很好地模拟交通场景。

#### 4. Available Actions and Expansion（可用动作和扩展）

定义一组高层次的动作集（例如，保持当前速度、加速或减速、保持与前车的时间间隔、在某个停止点停车、左/右变道）。在每个节点进行选择时，首先检查每个动作的前提条件是否满足，然后选择适当的动作进行扩展。

#### 5. Cost Function and Backpropagation（成本函数和反向传播）

为每辆车定义成本函数，包括车道变更成本、速度偏离成本、加速度成本、与障碍物和其他车辆的距离成本以及无效状态（如碰撞）的高成本。此外，还引入了一个合作成本函数，考虑其他车辆的成本，使用合作因子 λ 来调整每个交通参与者的合作程度。λ = 0 表示完全自私行为，λ = 1 表示完全合作行为。合作成本函数用于在反向传播过程中更新MCTS搜索树。

#### 6. Considered Vehicles and Decision Nodes（考虑的车辆和决策节点）

在规划过程中，只考虑与自车在一定距离内的车辆。对于直接与自车互动的车辆，使用动作集进行推演；对于不直接互动的车辆，使用默认策略进行推演。所有车辆的成本函数都会影响自车的合作成本函数。

#### 7. Terminal Nodes（终端节点）

如果达到时间范围 \( T_{final} \) 或者状态无效（例如发生碰撞），则节点被标记为终端节点。

#### 总结

这些扩展和调整使得MCTS算法能够在自动驾驶领域中更好地应用，特别是在需要实时决策和多车合作的复杂场景中。通过考虑同时决策、默认行为模型、合作成本函数等因素，MCTS算法能够生成有效的合作规划，实现自动驾驶车辆在复杂交通环境中的安全和高效运行。

### 实验部分（EXPERIMENTS）

在本文的实验部分，研究人员设计了一系列模拟场景来验证TCMP-MCTS算法在实际自动驾驶中的效果。主要包括以下几个实验场景：

#### A. 两车并道场景

在这个简单的实验中，右车道即将结束，车辆P1必须并入左车道。研究人员探讨了三种不同的解决方案：
1. **P2保持速度，P1减速**：这种情况下，P1需要大幅减速以避免撞上车道末端，表现为非合作行为。
2. **P2平滑加速，P1并入其后**：P2稍微加速，给P1创造机会以较低速度并入。
3. **P2平滑减速，P1保持速度并入其前**：P2稍微减速，让P1在其前方并入。

结果表明，随着合作因子λ的增加，总成本减少，但P2的成本增加，展示了不同程度的合作行为。

#### B. 多车并道场景

在更复杂的四车并道场景中，右车道结束，蓝色车辆需要并入左车道。实验结果显示，自车（红色）减速以便蓝色车辆并入，并且后方的白色车辆也需要减速。TCMP-MCTS算法在这种场景中能够生成有效的合作行为，优化整体交通流。

#### C. 拥挤交通下的并道场景

在三车并道的场景中，自车预见到中间车道的蓝色车辆可能会变道，因此保持速度而不减速。实际运行中，蓝色车辆确实变道，自车能够安全并入而不显著扰乱交通流。

#### 讨论

实验表明，TCMP-MCTS算法在假设所有交通参与者行为理性的前提下，能够生成合理的合作行为，即使在面对其他车辆做出次优决策的情况下也表现出一定的鲁棒性。这主要是因为在MCTS搜索树中，决策路径包含了对不同动作的最佳响应。

### 结论

通过上述实验，TCMP-MCTS算法展示了其在自动驾驶场景中的有效性，能够生成类似人类驾驶员的合作行为，如加速、减速或变道以让其他车辆并入。未来工作将进一步优化轨迹生成的舒适性，并在更多参考场景中进行比较和评估。

这些实验验证了算法在复杂动态环境中的应用潜力，展示了其在实际自动驾驶中的实用性和鲁棒性。
